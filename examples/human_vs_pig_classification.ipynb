{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human vs Pig Classification\n",
    "\n",
    "The distribution of k-mers in a genome can act as a _signature_ for a given species. In this notebook, we will exploit this fact by training a neural network to distinguish between genome extracts from a human and pig genome. We will use `torchmers` to encode DNA sequences into their k-mer spectra and feed the counts to a [multilayer perceptron](https://en.wikipedia.org/wiki/Multilayer_perceptron)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Data\n",
    "\n",
    "We will use the first chromosome from a human and pig reference genome as training and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 66.0M  100 66.0M    0     0  2393k      0  0:00:28  0:00:28 --:--:-- 2433k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 79.7M  100 79.7M    0     0  2357k      0  0:00:34  0:00:34 --:--:-- 2384k\n"
     ]
    }
   ],
   "source": [
    "!curl https://ftp.ensembl.org/pub/release-110/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna.chromosome.1.fa.gz | gunzip > human.fasta\n",
    "!curl https://ftp.ensembl.org/pub/release-110/fasta/sus_scrofa/dna/Sus_scrofa.Sscrofa11.1.dna.primary_assembly.1.fa.gz | gunzip > pig.fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preparation\n",
    "\n",
    "The training dataset will consists of non-overlapping patches from the DNA sequences of length `patch_length`. Extracts from the human genome will have the label `0` assigned while pig segments will have the label `1`.\n",
    "\n",
    "10,000 segments from each species's will serve as validation data. We choose a fixed number per species here to offset the different lengths of the two chromosomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from Bio import SeqIO\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torchmers.modules import KMerFrequencyEncoder, MLP\n",
    "from torchmers.tokenizers import Tokenizer\n",
    "from torchmers.utils import k_mer_from_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNADataset(Dataset):\n",
    "    def __init__(self, fasta_path, patch_length, tokenizer, label):\n",
    "        self.sequences = ''.join(\n",
    "            str(record.seq) for record in SeqIO.parse(fasta_path, 'fasta')\n",
    "        )\n",
    "        self.patch_length = patch_length\n",
    "        self.tokenizer = tokenizer\n",
    "        self.label = label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences) // self.patch_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        patch = self.sequences[idx * self.patch_length:(idx + 1) * self.patch_length]\n",
    "        tokens = self.tokenizer.encode(patch)\n",
    "        return tokens, self.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer.from_name('DNA')\n",
    "\n",
    "patch_length = 1024\n",
    "batch_size = 512\n",
    "device = 'cuda'\n",
    "\n",
    "labels = {\n",
    "    'human': 0,\n",
    "    'pig': 1\n",
    "}\n",
    "\n",
    "def load_dataset(species, test_samples=10_000):\n",
    "    dataset = DNADataset(\n",
    "        f'{species}.fasta',\n",
    "        patch_length,\n",
    "        tokenizer,\n",
    "        label=labels[species]\n",
    "    )\n",
    "\n",
    "    train_split, test_split = random_split(\n",
    "        dataset,\n",
    "        [len(dataset) - test_samples, test_samples]\n",
    "    )\n",
    "\n",
    "    return train_split, test_split\n",
    "\n",
    "\n",
    "human_train, human_test = load_dataset('human')\n",
    "pig_train, pig_test = load_dataset('pig')\n",
    "\n",
    "train_set = human_train + pig_train\n",
    "test_set = human_test + pig_test\n",
    "\n",
    "train_batches = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "test_batches = DataLoader(test_set, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model\n",
    "\n",
    "The classification model will consists of two main components: a k-mer frequency encoder layer that efficiently encodes DNA sequences to their frequency spectra and a MLP with a single layer. In fact, since the MLP does not contain any hidden layers in the default configuration, it boils down to a linear model that will be fitted via SGD.\n",
    "\n",
    "Both the k-mer frequency encoder and MLP class are part of the `torchmers` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the length of the k-mers here\n",
    "k = 7\n",
    "\n",
    "model = nn.Sequential(\n",
    "    KMerFrequencyEncoder(k=k, log_counts=True),\n",
    "    MLP(\n",
    "        input_dim=4 ** k,\n",
    "        hidden_dim=256,\n",
    "        output_dim=1,\n",
    "        num_layers=1,\n",
    "        bias=False\n",
    "    ),\n",
    "    nn.Flatten(0, 1)\n",
    ").to(device)\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing the network definition reveals that it contains only a single linear layer that maps from the k-mer spectrum with $$k^4$$ entries to a single unit, corresponding to the binary classification logit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): KMerFrequencyEncoder()\n",
       "  (1): MLP(\n",
       "    (net): Sequential(\n",
       "      (0): Linear(in_features=16384, out_features=1, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (2): Flatten(start_dim=0, end_dim=1)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model will be trained with SGD for 10 epochs. After each epoch, the loss and classificaton accuracy for the test dataset will be computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN | EPOCH 0 | loss: 0.2105, acc: 84.62: 100%|██████████| 960/960 [00:10<00:00, 89.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID | EPOCH 0 | loss: 0.3538, acc: 81.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN | EPOCH 1 | loss: 0.3906, acc: 69.23: 100%|██████████| 960/960 [00:10<00:00, 90.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID | EPOCH 1 | loss: 0.3542, acc: 81.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN | EPOCH 2 | loss: 0.4727, acc: 61.54: 100%|██████████| 960/960 [00:10<00:00, 90.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID | EPOCH 2 | loss: 0.3613, acc: 81.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN | EPOCH 3 | loss: 0.5518, acc: 69.23: 100%|██████████| 960/960 [00:10<00:00, 90.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID | EPOCH 3 | loss: 0.3547, acc: 81.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN | EPOCH 4 | loss: 0.3146, acc: 92.31: 100%|██████████| 960/960 [00:10<00:00, 90.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID | EPOCH 4 | loss: 0.3526, acc: 81.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN | EPOCH 5 | loss: 0.1497, acc: 92.31: 100%|██████████| 960/960 [00:10<00:00, 90.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID | EPOCH 5 | loss: 0.3546, acc: 81.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN | EPOCH 6 | loss: 0.3143, acc: 84.62: 100%|██████████| 960/960 [00:10<00:00, 90.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID | EPOCH 6 | loss: 0.3535, acc: 81.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN | EPOCH 7 | loss: 0.4549, acc: 69.23: 100%|██████████| 960/960 [00:10<00:00, 90.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID | EPOCH 7 | loss: 0.3650, acc: 81.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN | EPOCH 8 | loss: 0.3700, acc: 76.92: 100%|██████████| 960/960 [00:10<00:00, 90.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID | EPOCH 8 | loss: 0.3662, acc: 80.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN | EPOCH 9 | loss: 0.5026, acc: 76.92: 100%|██████████| 960/960 [00:10<00:00, 90.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID | EPOCH 9 | loss: 0.3560, acc: 81.42\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    model.train()\n",
    "\n",
    "    with tqdm(train_batches) as pbar:\n",
    "        for seqs, labels in pbar:\n",
    "            seqs = seqs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            logits = model(seqs)\n",
    "            \n",
    "            loss = F.binary_cross_entropy_with_logits(logits, labels.float())\n",
    "            loss.backward()\n",
    "\n",
    "            accuracy = ((logits > 0) == labels).float().mean().item() * 100\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            pbar.set_description(f'TRAIN | EPOCH {epoch} | loss: {loss.item():.4f}, acc: {accuracy:.2f}')\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    val_loss = 0\n",
    "    val_corr = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for seqs, labels in test_batches:\n",
    "            seqs = seqs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            logits = model(seqs)\n",
    "\n",
    "            val_loss += F.binary_cross_entropy_with_logits(logits, labels.float()).item()\n",
    "            val_corr += ((logits > 0) == labels).float().sum().item()\n",
    "        \n",
    "        val_loss_avg = val_loss / len(test_batches)\n",
    "        val_acc = val_corr / len(test_set) * 100\n",
    "        \n",
    "    print(f'VALID | EPOCH {epoch} | loss: {val_loss_avg:.4f}, acc: {val_acc:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the model is capable of classifying between human and pig genome extracts with an accuracy of around 81%. This value could likely be further improved by using larger k-mers, a deeper model or more hyperparameter tuning in general."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting the Model\n",
    "\n",
    "Since our single-layer neural network is essentially just a linear model, we can inspect the only weight matrix to get a hint on what k-mers are most important for the classification decision.\n",
    "\n",
    "Human has the label `0`, thus the weights with the lowest numerical value correspond to the most important features for that class. For pig, the weights with the highest value indicate the most important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 most important k-mers for human:\n",
      "0.351 AAAAAAA\n",
      "0.334 GTAATCC\n",
      "0.332 GGATTAC\n",
      "0.298 GTCTCGC\n",
      "0.290 TCGAACT\n",
      "0.287 TCAAGCG\n",
      "0.270 CGCGGTG\n",
      "0.268 GCGATCC\n",
      "0.257 ACAGGCG\n",
      "0.249 GGAGTGC\n",
      "\n",
      "Top 10 most important k-mers for pig:\n",
      "0.300 TCCCCCC\n",
      "0.302 GGTTCGA\n",
      "0.326 TCGAACC\n",
      "0.330 CTAGTCG\n",
      "0.348 CGATCCC\n",
      "0.352 GGGGGGA\n",
      "0.370 GGATCGA\n",
      "0.400 TCGATCC\n",
      "0.805 GGGGGGG\n",
      "0.818 CCCCCCC\n"
     ]
    }
   ],
   "source": [
    "weights = model[1].net[0].weight[0]\n",
    "weight_index_pairs = list(zip(*weights.sort()))\n",
    "\n",
    "print('Top 10 most important k-mers for human:')\n",
    "\n",
    "for weight, i in weight_index_pairs[:10]:\n",
    "    print(f'{-weight.item():.3f} {k_mer_from_index(i.item(), k)}')\n",
    "\n",
    "print()\n",
    "print('Top 10 most important k-mers for pig:')\n",
    "\n",
    "for weight, i in weight_index_pairs[-10:]:\n",
    "    print(f'{weight.item():.3f} {k_mer_from_index(i.item(), k)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
